---
alwaysApply: true
---

# 本地化大规模语料分析工具技术方案（通用自定义维度版）
## 一、项目核心定位
### 1.1 核心目标
开发**纯本地化、无服务端依赖**的通用语料分析脚本，聚焦包含“PPT主题生成”背景的用户语料（分为「请求语料」（需求分析）和「反馈语料」（需求反馈）两类），支持大规模数据输入/分析，可打包为EXE执行文件；核心能力是对语料进行**自定义维度/关键词的多维度分析**（支持任意关键词如“老师/教学/权限/风格”等，而非绑定“页数”），输出文字、表格、图表多层级结果，且在“PPT主题生成”场景下的分析效果优于通用大模型。

### 1.2 核心差异化（优于通用大模型）
| 对比维度       | 本工具                          | 通用大模型                      |
|----------------|---------------------------------|---------------------------------|
| 大规模数据处理 | 支持20万+行语料分批分析，无截断 | 单次处理上限≤1万行，易丢失信息  |
| 场景贴合度     | 内置PPT主题生成专属业务词典/规则，可绑定任意自定义维度分析，精准无泛化 | 泛化性强，易偏离PPT场景核心，自定义维度分析浅 |
| 自定义维度分析 | 支持任意关键词/维度（如“老师/教学”），多维度拆解分析，权重可配置 | 自定义维度分析泛化，无业务场景约束，维度单一 |
| 本地化能力     | 离线运行，无数据泄露/API成本    | 需联网，敏感语料有泄露风险      |
| 输出结构化     | 输出固定格式的多维度分析结果（图/表/文字），适配自定义维度 | 输出非结构化，需二次整理        |

### 1.3 核心约束
- 无服务端/云端依赖，所有计算本地完成；
- 优先实现分析功能，UI为可选轻量化方案（tkinter），Electron为扩展选项；
- 支持Windows平台EXE打包，兼顾分析性能与打包体积；
- 分析框架完全解耦具体关键词，适配任意自定义维度（如“老师/教学/权限/风格/页数”等）。

## 二、技术栈选型（全本地化）
| 技术类别       | 选型                          | 选型理由                                                                 |
|----------------|-------------------------------|--------------------------------------------------------------------------|
| 核心语言       | Python 3.10+                  | 数据处理/ NLP生态完善，易打包，支持大规模数据分批次处理                  |
| 大规模数据处理 | Pandas + Dask                 | Pandas适配常规大规模（≤10万行），Dask扩展至超大规模（20万+行），无内存溢出 |
| NLP分析        | jieba（分词）+ BM25（关键词）+ SnowNLP（情感）+ 自定义规则引擎 | 纯Python实现，本地化无依赖，支持自定义维度/关键词的权重配置              |
| 可视化         | Matplotlib + Seaborn          | 本地生成图表（饼图/柱状图/热力图/箱线图等），无云端渲染依赖              |
| 输出格式       | Markdown + Excel + PNG（图表） | 结构化输出，可直接复用，支持自定义维度的动态报告生成                      |
| 打包工具       | PyInstaller                   | 成熟的Python→EXE工具，支持打包依赖文件（词典/配置）                      |
| UI（轻量化）   | Tkinter                       | 内置库，无需额外依赖，满足基础交互（自定义关键词输入/文件选择/分析触发）  |
| UI（扩展）     | Electron + Python API         | 可选，需前端开发，优先级低于核心分析功能                                |

## 三、核心功能模块设计
### 3.1 模块总架构
```
├── src/
│   ├── main.py                # 主入口（UI交互+流程调度）
│   ├── data_io/               # 大规模数据输入/输出模块
│   │   ├── data_loader.py     # 分批读取Excel/CSV（支持20万+行）
│   │   └── result_exporter.py # 输出MD/Excel/图表（适配自定义维度）
│   ├── preprocess/            # 语料预处理模块
│   │   ├── cleaner.py         # 文本清洗（去噪/去重/标准化）
│   │   ├── tokenizer.py       # 分词+PPT场景专属词典加载+停用词过滤
│   │   └── dimension_marker.py # 自定义维度/关键词标记（替代原keyword_marker）
│   ├── analyzer/              # 核心分析引擎（双场景+通用维度）
│   │   ├── base_analyzer.py   # 分析基类（通用统计/可视化）
│   │   ├── request_analyzer.py # 请求语料分析（需求分析，适配自定义维度）
│   │   └── feedback_analyzer.py # 反馈语料分析（需求反馈，适配自定义维度）
│   ├── config/                # 配置模块（通用化，无硬编码维度）
│   │   ├── ppt_business_dict.txt  # PPT场景专属业务词典（通用术语）
│   │   ├── stopwords.txt      # 通用+PPT场景停用词
│   │   ├── synonym_dict.txt   # 通用同义词词典（可扩展自定义维度）
│   │   └── config.json        # 分析规则配置（动态适配自定义维度）
│   └── utils/                 # 工具函数（缓存/日志/异常处理）
├── requirements.txt           # 依赖清单
├── build.spec                 # PyInstaller打包配置
└── templates/                 # 动态报告模板（适配自定义维度）
```

### 3.2 核心模块详细设计（通用化解耦）
#### 3.2.1 大规模数据输入模块（data_io/data_loader.py）
**核心能力**：支持20万+行Excel/CSV语料输入，解决内存溢出问题，完全通用无维度绑定。
- 分批读取策略：默认按1万行/批次读取，可配置批次大小；
- 格式兼容：支持.xlsx/.csv，自动识别编码（GBK/UTF-8）；
- 数据校验：自动过滤空行/无效行（如仅含标点/数字的语料）；
- 增量加载：支持追加式分析（基于历史分析结果，无需重复处理全量数据）；
- 通用字段适配：仅要求语料文件包含“content”（语料内容）、“type”（请求/反馈）字段，其余字段（如时间/场景）可选，无硬编码依赖。

**关键代码逻辑示例**：
```python
import dask.dataframe as dd
import pandas as pd

def load_large_corpus(file_path, batch_size=10000):
    """加载大规模语料，返回分批迭代器（通用化，无维度绑定）"""
    # 自动识别文件格式
    read_kwargs = {"encoding": "utf-8", "low_memory": False}
    if file_path.endswith('.xlsx'):
        ddf = dd.read_excel(file_path, engine='openpyxl', **read_kwargs)
    else:
        ddf = dd.read_csv(file_path, **read_kwargs)
    
    # 校验核心字段
    required_cols = ["content"]
    if not all(col in ddf.columns for col in required_cols):
        raise ValueError(f"语料文件必须包含核心字段：{required_cols}")
    
    # 分批加载并过滤无效数据
    for i in range(0, len(ddf), batch_size):
        batch = ddf.iloc[i:i+batch_size].compute()  # 仅加载当前批次到内存
        # 过滤空值/无效行（通用规则，无维度绑定）
        batch = batch[
            batch['content'].notna() 
            & batch['content'].str.strip() != ''
            & batch['content'].str.len() >= 2  # 过滤过短无意义语料
        ]
        yield batch
```

#### 3.2.2 语料预处理模块（preprocess/）
**核心目标**：通用化预处理，支持任意自定义维度/关键词的权重强化，无硬编码维度（如“页数”）。
| 子模块               | 功能描述（通用化）|
|----------------------|--------------------------------------------------------------------------|
| cleaner.py           | 文本通用去噪（特殊符号/多余空格）、标准化（数字转文字/统一句式）、去重（重复语料合并），无维度绑定 |
| tokenizer.py         | jieba分词+PPT场景专属通用词典加载（如“PPT主题/汇报/演示/模板”）、通用停用词过滤（排除无意义词） |
| dimension_marker.py  | 接收用户输入的**任意自定义维度/关键词**（如“老师/教学/权限”），支持多关键词组合；将关键词及同义词的分析权重提升N倍（可配置，默认3倍），确保分析聚焦自定义维度 |

**自定义维度标记核心逻辑（通用化）**：
```python
def mark_custom_dimension_weight(tokens, custom_dimensions, synonym_dict, weight_multiplier=3.0):
    """
    通用化自定义维度权重标记
    :param tokens: 分词后的语料tokens
    :param custom_dimensions: 用户输入的自定义维度/关键词列表（如["老师", "教学"]）
    :param synonym_dict: 通用同义词词典（可扩展）
    :param weight_multiplier: 权重提升倍数
    :return: 带权重的token字典
    """
    weight_dict = {}
    for token in tokens:
        # 匹配自定义维度或其同义词（通用逻辑，无硬编码）
        is_target_dim = False
        for dim in custom_dimensions:
            if token == dim or token in synonym_dict.get(dim, []):
                weight_dict[token] = weight_multiplier  # 目标维度权重提升
                is_target_dim = True
                break
        if not is_target_dim:
            weight_dict[token] = 1.0  # 普通词基础权重
    return weight_dict
```

#### 3.2.3 双场景通用分析引擎（analyzer/）
**核心目标**：完全解耦具体维度，支持对**任意自定义维度**（如“老师/教学/权限”）的多维度分析，区分「请求语料」（需求分析）和「反馈语料」（需求反馈），输出通用化多维度结果。

##### （1）通用分析维度框架（适配所有自定义维度）
无论用户输入的自定义维度是“老师”“教学”还是“页数”，均按以下通用维度分析（动态适配维度内容）：
| 通用分析维度       | 适用场景       | 核心分析逻辑（通用化）|
|--------------------|----------------|--------------------------------------------------------------------------|
| 频次分布           | 请求/反馈      | 自定义维度相关内容的出现频次、占比、排名（如“老师”相关语料占比/“教学”相关请求数） |
| 关联特征           | 请求/反馈      | 自定义维度与其他诉求的关联（如“老师”常关联“PPT模板简单化”“教学案例展示”） |
| 态度/情感倾向      | 请求/反馈      | 自定义维度相关内容的主观态度（正面/负面/中性），如“教学相关PPT页数太多（负面）” |
| 场景关联           | 请求/反馈      | 自定义维度对应的PPT使用场景（如“老师”→“课堂演示”，“教学”→“学生汇报”） |
| 问题/需求归类      | 请求（需求）| 自定义维度相关的需求分类（如“教学”→“新增教学案例模块”“优化教学PPT模板”） |
| 问题/反馈归类      | 反馈（效果）| 自定义维度相关的反馈问题分类（如“老师”→“PPT操作复杂”“教学内容展示不全”） |
| 数值特征（可选）| 请求/反馈      | 若自定义维度含数值（如“页数/字号”），分析均值/中位数/极值；无数值则跳过 |
| 趋势特征（可选）| 请求/反馈      | 若语料含时间字段，分析自定义维度相关内容的时间趋势；无时间则跳过 |

##### （2）请求语料分析器（request_analyzer.py）
聚焦“用户对PPT生成的需求”，以自定义维度“教学”为例，输出通用维度分析结果（替换原“页数”示例）：
| 通用分析维度       | 具体内容（以“教学”为自定义维度）|
|--------------------|--------------------------------------------------------------------------|
| 频次分布           | 教学相关请求占总请求的40%，其中“教学案例展示”占15%、“教学PPT模板”占12%、“教学步骤拆解”占8% |
| 关联特征           | “教学”常关联“简单风格”（60%）、“10-15页”（55%）、“课堂演示”（70%）|
| 态度/情感倾向      | 教学相关请求中，中性需求（仅提诉求）占80%，正面（“希望增加教学模块”）占15%，无负面 |
| 场景关联           | “教学”→ 课堂演示（70%）、学生汇报（20%）、教学培训（10%）|
| 问题/需求归类      | 教学相关需求分为：模板定制（45%）、内容模块新增（30%）、格式适配（25%）|
| 数值特征（可选）| 教学相关PPT请求的平均页数12页，中位数10页，主流需求10-15页 |

##### （3）反馈语料分析器（feedback_analyzer.py）
聚焦“用户对生成PPT的反馈”，以自定义维度“老师”为例，输出通用维度分析结果：
| 通用分析维度       | 具体内容（以“老师”为自定义维度）|
|--------------------|--------------------------------------------------------------------------|
| 频次分布           | 老师相关反馈占总反馈的35%，其中“操作复杂”占12%、“内容适配差”占10%、“效果满意”占8% |
| 关联特征           | “老师”常关联“操作指引缺失”（65%）、“字体太小”（40%）、“案例不足”（35%）|
| 态度/情感倾向      | 老师相关反馈中，负面（“操作复杂不适合老师使用”）占50%，中性占30%，正面（“教学PPT适配性好”）占20% |
| 场景关联           | “老师”→ 课堂教学（80%）、课后作业点评（15%）、公开课演示（5%）|
| 问题/反馈归类      | 老师相关反馈分为：操作体验差（40%）、内容适配不足（30%）、格式问题（20%）、其他（10%）|
| 整改建议           | 基于反馈生成自定义维度优化建议（如“针对老师场景优化PPT操作流程，增加教学案例模板”） |

##### （4）通用多维度可视化生成
为**任意自定义维度**的每个分析维度生成对应图表，支持本地保存为PNG，无硬编码图表类型：
| 通用分析维度       | 图表类型（通用适配）| 示例（以“教学”为自定义维度）|
|--------------------|-------------------------|---------------------------------|
| 频次分布           | 饼图/柱状图             | 教学相关需求分类占比饼图        |
| 关联特征           | 热力图/词云             | 教学维度-场景关联热力图         |
| 态度/情感倾向      | 堆叠柱状图              | 教学相关反馈的情感分布堆叠图    |
| 数值特征（可选）| 箱线图/折线图           | 教学PPT请求页数的数值分布箱线图 |
| 趋势特征（可选）| 折线图                  | 教学相关请求的周度趋势折线图    |

#### 3.2.4 通用化输出模块（data_io/result_exporter.py）
**核心能力**：输出包含「文字说明+表格+图表」的结构化分析报告，报告内容动态适配用户输入的自定义维度（如“老师/教学”），无硬编码维度。

##### （1）输出格式（通用化）
| 输出格式       | 内容（动态适配自定义维度）|
|----------------|--------------------------------------------------------------------------|
| Markdown报告   | 核心分析结论（自定义维度）、数据表格、图表引用，适配Cursor代码生成/文档复用 |
| Excel报告      | 分Sheet存储“维度概览”“频次分布”“关联特征”“情感/态度”“整改建议”，通用化表头 |
| 图表文件       | 所有可视化图表以PNG格式保存，文件名含自定义维度标识（如“教学_频次分布.png”） |

##### （2）通用Markdown报告模板（动态适配自定义维度）
```markdown
# PPT主题生成场景语料分析报告（聚焦：{{自定义维度}}）
## 1. 核心分析结论
### 1.1 数据概览
- 总语料数：{{总条数}}
- {{自定义维度}}相关语料数：{{目标条数}}，占比：{{目标占比}}
- 语料类型分布：请求语料（{{请求数}}）、反馈语料（{{反馈数}}）

### 1.2 {{自定义维度}}-请求语料分析（需求分析）
- 核心需求：{{Top3需求}}
- 频次最高的关联诉求：{{Top3关联诉求}}
- 主流场景：{{Top3场景}}

### 1.3 {{自定义维度}}-反馈语料分析（效果反馈）
- 情感分布：正面（{{正面占比}}）、中性（{{中性占比}}）、负面（{{负面占比}}）
- 核心问题：{{Top3问题}}
- 优化建议：{{Top3建议}}

## 2. 数据表格（{{自定义维度}}）
| {{自定义维度}}相关分类 | 频次 | 占比 | 关联场景 | 态度倾向 |
|------------------------|------|------|----------|----------|
| {{分类1}}              | {{频次1}} | {{占比1}} | {{场景1}} | {{态度1}} |
| {{分类2}}              | {{频次2}} | {{占比2}} | {{场景2}} | {{态度2}} |

## 3. 可视化图表
### 3.1 {{自定义维度}}相关频次分布
![{{自定义维度}}_频次分布](charts/{{自定义维度}}_频次分布.png)
### 3.2 {{自定义维度}}-场景关联热力图
![{{自定义维度}}_场景关联](charts/{{自定义维度}}_场景关联.png)
```

## 四、大规模数据性能优化（通用化）
### 4.1 内存优化
- 分批处理：所有分析按1万行/批次执行，处理完成后释放当前批次内存，无维度相关内存占用；
- 延迟加载：图表生成仅在最终输出时执行，中间过程仅保留统计结果，不生成图表；
- 通用数据压缩：合并重复语料（按“content+自定义维度”维度去重），减少数据量。

### 4.2 速度优化
- 通用缓存机制：分词/自定义维度标记结果本地缓存，重复分析同一语料+同一维度时直接复用；
- 多线程处理：启用4线程并行处理分批语料（IO密集型操作），通用化线程池无维度绑定；
- 轻量级通用算法：放弃深度学习模型，采用“规则+统计算法”（BM25/SnowNLP），分析速度提升5倍。

### 4.3 性能指标（20万行语料+任意自定义维度）
| 指标           | 数值                          |
|----------------|-------------------------------|
| 数据加载时间   | ≤60秒                         |
| 预处理时间     | ≤120秒                        |
| 双场景分析时间 | ≤180秒                        |
| 报告生成时间   | ≤30秒                         |
| 内存占用       | ≤2GB                          |
| 总耗时         | ≤6分钟                        |

## 五、EXE打包方案（通用化，无维度绑定）
### 5.1 打包工具与命令
使用PyInstaller打包，优先选择“文件夹模式”（避免单文件模式启动慢），通用化配置无维度依赖：
```bash
# 安装依赖
pip install -r requirements.txt

# 打包命令（Windows，通用化配置）
pyinstaller --onedir ^
--windowed ^
--icon=icon.ico ^
--add-data "src/config;config" ^  # 通用配置文件，无硬编码维度
--add-data "src/templates;templates" ^  # 通用报告模板
--exclude-module tkinter.demos ^  # 剔除tkinter冗余模块
--optimize=2 ^  # 代码优化
--name "PPT语料分析工具" ^  # 通用命名
src/main.py
```

### 5.2 打包优化（控制体积）
| 优化手段               | 效果                          |
|------------------------|-------------------------------|
| 剔除冗余依赖           | 移除torch/tensorflow等非必要库，体积减少500MB+ |
| 压缩通用静态资源       | 词典/模板文件压缩，体积减少20MB+ |
| 单文件模式（可选）     | 打包为单个EXE，体积≈80MB（文件夹模式≈120MB） |

### 5.3 打包后使用流程（通用化）
1. 解压EXE文件夹（或直接运行单文件EXE）；
2. 启动主程序，通过轻量UI选择语料文件（Excel/CSV）；
3. 输入**任意自定义维度/关键词**（如“老师/教学”，支持多关键词逗号分隔），选择分析类型（请求/反馈/双场景）；
4. 点击“开始分析”，等待分析完成；
5. 在指定输出目录查看动态生成的MD/Excel报告+图表文件（文件名含自定义维度标识）。

## 六、UI方案（低优先级，通用化）
### 6.1 轻量化方案（主推）
基于Tkinter实现基础通用交互界面，核心功能无维度绑定：
- 文件选择框：选择待分析的语料文件（Excel/CSV）；
- 自定义维度输入框：输入任意关键词（支持多关键词，逗号分隔）；
- 分析类型选择：请求语料/反馈语料/双场景；
- 权重倍数配置（可选）：设置自定义维度的权重提升倍数（默认3倍）；
- 进度条：显示通用分析进度（加载/预处理/分析/输出）；
- 输出路径选择：指定报告保存路径。

### 6.2 扩展方案（Electron）
如需更美观的UI，可采用“Electron + Python API”架构，通用化交互逻辑：
- Electron负责前端通用界面（文件选择、自定义维度输入、结果展示）；
- Python脚本封装为通用本地API，Electron通过子进程调用，无维度绑定；
- 优势：界面更美观，支持拖拽上传；劣势：打包体积增大（≈200MB），开发成本高。

## 七、核心优势与验证（优于大模型，通用化）
### 7.1 核心优势
1. **通用化维度适配**：支持任意自定义维度/关键词分析（如“老师/教学/权限/页数”），无硬编码绑定，适配所有PPT主题生成场景的分析需求；
2. **大规模处理能力**：20万行语料无压力，大模型需人工拆分且易丢失信息；
3. **场景精准无泛化**：内置PPT主题生成专属通用规则，自定义维度分析不偏离场景（大模型易泛化）；
4. **本地化安全**：无数据泄露，无API成本，离线可用；
5. **输出结构化通用**：报告动态适配自定义维度，可直接复用，无需二次整理（大模型输出需手动调整）。

### 7.2 验证方法（通用化）
对比测试：使用同一批20万行PPT主题生成相关语料，分别用本工具（自定义维度“教学”）和通用大模型分析：
- 本工具：输出精准的“教学”维度频次、关联场景、情感倾向、需求/问题归类，图表/表格/文字完整且贴合PPT场景；
- 大模型：“教学”维度分析泛化（混入通用PPT建议），无大规模数据处理能力，输出无结构化表格/图表。

## 八、开发与落地路线图
### Phase 1：核心通用功能开发（2周）
1. 完成通用化数据加载/预处理模块（支持20万行语料，无维度绑定）；
2. 完成双场景通用分析引擎（适配任意自定义维度）；
3. 实现通用化自定义维度权重标记逻辑；
4. 完成通用化MD/Excel/图表输出。

### Phase 2：打包与轻量化UI（1周）
1. 完成PyInstaller通用打包配置，测试EXE运行；
2. 实现Tkinter基础通用UI；
3. 优化性能（内存/速度）。

### Phase 3：测试与优化（1周）
1. 用20万行模拟语料+不同自定义维度（“老师/教学/权限/页数”）测试分析效果；
2. 修复打包/运行中的Bug；
3. 完善通用报告模板，优化可视化效果。

### Phase 4：扩展（可选，低优先级）
1. 实现Electron通用UI；
2. 支持更多通用输出格式（如PPT报告）；
3. 扩展通用同义词词典（适配更多行业维度）。

## 九、依赖清单（requirements.txt，通用化）
```
python==3.10.12
pandas==2.1.4
dask==2023.12.1
openpyxl==3.1.2
jieba==0.42.1
snownlp==0.12.3
matplotlib==3.8.2
seaborn==0.13.2
pyinstaller==5.13.2
rank_bm25==0.2.2
```